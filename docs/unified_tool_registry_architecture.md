# é‡æ–°è®¾è®¡ï¼šç»Ÿä¸€å·¥å…·æ³¨å†Œè¡¨ + æ™ºèƒ½è·¯ç”± + MCPç»Ÿä¸€æ‰§è¡Œ

## ğŸ¯ **æ ¸å¿ƒè®¾è®¡ç†å¿µ**

### ğŸ“‹ **è®¾è®¡åŸåˆ™**
1. **ç»Ÿä¸€æ³¨å†Œè¡¨** - ä¸€ä¸ªä¸­å¤®åŒ–çš„å·¥å…·æ³¨å†Œè¡¨ï¼Œè®°å½•æ‰€æœ‰å¹³å°çš„å·¥å…·
2. **æ™ºèƒ½è·¯ç”±** - åŸºäºå·¥å…·ç‰¹æ€§ã€æˆæœ¬ã€æ€§èƒ½çš„æ™ºèƒ½é€‰æ‹©ç®—æ³•
3. **MCPç»Ÿä¸€æ‰§è¡Œ** - é€šè¿‡æ ‡å‡†MCPåè®®æ‰§è¡Œæ‰€æœ‰å¹³å°çš„å·¥å…·
4. **é€æ˜åˆ‡æ¢** - ç”¨æˆ·æ— æ„ŸçŸ¥çš„å¹³å°åˆ‡æ¢ä½“éªŒ

### ğŸ—ï¸ **é‡æ–°è®¾è®¡çš„æ¶æ„å›¾**
```
                    ç”¨æˆ·è¯·æ±‚
                       â†“
                MCPBrainstorm
                (æ„å›¾ç†è§£)
                       â†“
                 å¤æ‚åº¦åˆ†æ
                       â†“
            [ç®€å•ä»»åŠ¡]     [å¤æ‚ä»»åŠ¡]
               â†“              â†“
         ç›´æ¥å·¥å…·æŸ¥è¯¢    MCPPlannerè§„åˆ’
               â†“              â†“
           InfiniteContext (ä¸Šä¸‹æ–‡å¢å¼º)
                       â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   ç»Ÿä¸€å·¥å…·æ³¨å†Œè¡¨      â”‚
              â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
              â”‚ â”‚ ACI.dev å·¥å…·    â”‚ â”‚
              â”‚ â”‚ MCP.so å·¥å…·     â”‚ â”‚
              â”‚ â”‚ Zapier å·¥å…·     â”‚ â”‚
              â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
                 å·¥å…·å‘ç°ä¸åŒ¹é…
                       â†“
                 æ™ºèƒ½è·¯ç”±å†³ç­–
                       â†“
              é€‰æ‹©æœ€ä¼˜å·¥å…·+å¹³å°
                       â†“
                MCPç»Ÿä¸€æ‰§è¡Œå¼•æ“
                       â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“             â†“             â†“             â†“
   ACI.dev MCP   MCP.so MCP   Zapier MCP   æœ¬åœ°MCP
     å®¢æˆ·ç«¯        å®¢æˆ·ç«¯        é€‚é…å™¨       å·¥å…·
        â†“             â†“             â†“             â†“
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
                   æ‰§è¡Œç»“æœ
                       â†“
                   è¿”å›ç”¨æˆ·
```

## ğŸ—‚ï¸ **ç»Ÿä¸€å·¥å…·æ³¨å†Œè¡¨è®¾è®¡**

### ğŸ“Š **å·¥å…·æ³¨å†Œè¡¨æ•°æ®ç»“æ„**
```python
class UnifiedToolRegistry:
    """ç»Ÿä¸€å·¥å…·æ³¨å†Œè¡¨"""
    
    def __init__(self):
        self.tools_db = {}  # å·¥å…·æ•°æ®åº“
        self.platform_clients = {
            "aci.dev": ACIDevMCPClient(),
            "mcp.so": MCPSoMCPClient(), 
            "zapier": ZapierMCPAdapter()
        }
        
    def register_tool(self, tool_info):
        """æ³¨å†Œå·¥å…·åˆ°ç»Ÿä¸€æ³¨å†Œè¡¨"""
        tool_id = f"{tool_info['platform']}:{tool_info['name']}"
        
        unified_tool = {
            # åŸºç¡€ä¿¡æ¯
            "id": tool_id,
            "name": tool_info["name"],
            "description": tool_info["description"],
            "category": tool_info["category"],
            "version": tool_info.get("version", "1.0.0"),
            
            # å¹³å°ä¿¡æ¯
            "platform": tool_info["platform"],  # "aci.dev", "mcp.so", "zapier"
            "platform_tool_id": tool_info["platform_tool_id"],
            "mcp_endpoint": tool_info["mcp_endpoint"],
            
            # åŠŸèƒ½ç‰¹æ€§
            "capabilities": tool_info["capabilities"],
            "input_schema": tool_info["input_schema"],
            "output_schema": tool_info["output_schema"],
            "supported_formats": tool_info.get("supported_formats", []),
            
            # æ€§èƒ½æŒ‡æ ‡
            "performance_metrics": {
                "avg_response_time": tool_info.get("avg_response_time", 1000),  # ms
                "success_rate": tool_info.get("success_rate", 0.95),
                "throughput": tool_info.get("throughput", 100),  # requests/min
                "reliability_score": tool_info.get("reliability_score", 0.9)
            },
            
            # æˆæœ¬ä¿¡æ¯
            "cost_model": {
                "type": tool_info.get("cost_type", "free"),  # free, per_call, subscription
                "cost_per_call": tool_info.get("cost_per_call", 0.0),
                "monthly_limit": tool_info.get("monthly_limit", -1),  # -1 = unlimited
                "currency": tool_info.get("currency", "USD")
            },
            
            # ä½¿ç”¨é™åˆ¶
            "limitations": {
                "rate_limit": tool_info.get("rate_limit", 1000),  # calls/hour
                "data_size_limit": tool_info.get("data_size_limit", 10),  # MB
                "concurrent_limit": tool_info.get("concurrent_limit", 10),
                "geographic_restrictions": tool_info.get("geo_restrictions", [])
            },
            
            # è´¨é‡è¯„åˆ†
            "quality_scores": {
                "user_rating": tool_info.get("user_rating", 4.0),  # 1-5
                "documentation_quality": tool_info.get("doc_quality", 0.8),
                "community_support": tool_info.get("community_support", 0.7),
                "update_frequency": tool_info.get("update_frequency", 0.8)
            },
            
            # å…ƒæ•°æ®
            "metadata": {
                "created_at": tool_info.get("created_at"),
                "updated_at": tool_info.get("updated_at"),
                "tags": tool_info.get("tags", []),
                "author": tool_info.get("author", ""),
                "license": tool_info.get("license", ""),
                "homepage": tool_info.get("homepage", "")
            }
        }
        
        self.tools_db[tool_id] = unified_tool
        return tool_id

# ç¤ºä¾‹å·¥å…·æ³¨å†Œ
registry = UnifiedToolRegistry()

# ACI.devå·¥å…·ç¤ºä¾‹
aci_tool = {
    "name": "google_calendar_integration",
    "description": "Google Calendar APIé›†æˆå·¥å…·",
    "category": "productivity",
    "platform": "aci.dev",
    "platform_tool_id": "google_calendar_v3",
    "mcp_endpoint": "https://api.aci.dev/mcp/google_calendar",
    "capabilities": ["schedule", "remind", "sync", "share"],
    "input_schema": {"type": "object", "properties": {"action": {"type": "string"}}},
    "output_schema": {"type": "object", "properties": {"result": {"type": "string"}}},
    "avg_response_time": 200,
    "success_rate": 0.98,
    "cost_type": "per_call",
    "cost_per_call": 0.001,
    "user_rating": 4.5
}

# MCP.soå·¥å…·ç¤ºä¾‹  
mcpso_tool = {
    "name": "advanced_data_analyzer",
    "description": "é«˜çº§æ•°æ®åˆ†æMCPå·¥å…·",
    "category": "data_analysis", 
    "platform": "mcp.so",
    "platform_tool_id": "data_analyzer_pro",
    "mcp_endpoint": "https://api.mcp.so/tools/data_analyzer",
    "capabilities": ["analyze", "visualize", "predict", "export"],
    "input_schema": {"type": "object", "properties": {"data": {"type": "array"}}},
    "output_schema": {"type": "object", "properties": {"analysis": {"type": "object"}}},
    "avg_response_time": 500,
    "success_rate": 0.96,
    "cost_type": "subscription",
    "monthly_limit": 1000,
    "user_rating": 4.3
}

# Zapierå·¥å…·ç¤ºä¾‹
zapier_tool = {
    "name": "slack_team_notification",
    "description": "Slackå›¢é˜Ÿé€šçŸ¥è‡ªåŠ¨åŒ–",
    "category": "communication",
    "platform": "zapier", 
    "platform_tool_id": "slack_webhook_v2",
    "mcp_endpoint": "https://zapier-mcp-bridge.com/slack_notification",
    "capabilities": ["message", "channel", "mention", "format"],
    "input_schema": {"type": "object", "properties": {"message": {"type": "string"}}},
    "output_schema": {"type": "object", "properties": {"status": {"type": "string"}}},
    "avg_response_time": 150,
    "success_rate": 0.99,
    "cost_type": "free",
    "user_rating": 4.7
}

# æ³¨å†Œå·¥å…·
registry.register_tool(aci_tool)
registry.register_tool(mcpso_tool)
registry.register_tool(zapier_tool)
```

### ğŸ” **å·¥å…·å‘ç°ä¸æœç´¢**
```python
class ToolDiscoveryEngine:
    """å·¥å…·å‘ç°å¼•æ“"""
    
    def __init__(self, registry: UnifiedToolRegistry):
        self.registry = registry
        
    def search_tools(self, query: str, filters: Dict = None) -> List[Dict]:
        """æœç´¢å·¥å…·"""
        filters = filters or {}
        
        # 1. æ–‡æœ¬åŒ¹é…
        text_matches = self._text_search(query)
        
        # 2. åº”ç”¨è¿‡æ»¤å™¨
        filtered_tools = self._apply_filters(text_matches, filters)
        
        # 3. ç›¸å…³æ€§æ’åº
        ranked_tools = self._rank_by_relevance(filtered_tools, query)
        
        return ranked_tools
    
    def _text_search(self, query: str) -> List[Dict]:
        """æ–‡æœ¬æœç´¢"""
        query_lower = query.lower()
        matches = []
        
        for tool_id, tool in self.registry.tools_db.items():
            score = 0.0
            
            # åç§°åŒ¹é… (æƒé‡: 40%)
            if query_lower in tool["name"].lower():
                score += 0.4
            
            # æè¿°åŒ¹é… (æƒé‡: 30%)
            if query_lower in tool["description"].lower():
                score += 0.3
                
            # ç±»åˆ«åŒ¹é… (æƒé‡: 20%)
            if query_lower in tool["category"].lower():
                score += 0.2
                
            # èƒ½åŠ›åŒ¹é… (æƒé‡: 10%)
            for capability in tool["capabilities"]:
                if query_lower in capability.lower():
                    score += 0.1
                    break
            
            if score > 0:
                tool_copy = tool.copy()
                tool_copy["relevance_score"] = score
                matches.append(tool_copy)
        
        return matches
    
    def _apply_filters(self, tools: List[Dict], filters: Dict) -> List[Dict]:
        """åº”ç”¨è¿‡æ»¤å™¨"""
        filtered = tools
        
        # å¹³å°è¿‡æ»¤
        if "platforms" in filters:
            filtered = [t for t in filtered if t["platform"] in filters["platforms"]]
        
        # ç±»åˆ«è¿‡æ»¤
        if "categories" in filters:
            filtered = [t for t in filtered if t["category"] in filters["categories"]]
        
        # æˆæœ¬è¿‡æ»¤
        if "max_cost" in filters:
            filtered = [t for t in filtered 
                       if t["cost_model"]["cost_per_call"] <= filters["max_cost"]]
        
        # æ€§èƒ½è¿‡æ»¤
        if "min_success_rate" in filters:
            filtered = [t for t in filtered 
                       if t["performance_metrics"]["success_rate"] >= filters["min_success_rate"]]
        
        return filtered
    
    def _rank_by_relevance(self, tools: List[Dict], query: str) -> List[Dict]:
        """æŒ‰ç›¸å…³æ€§æ’åº"""
        return sorted(tools, key=lambda x: x.get("relevance_score", 0), reverse=True)
```

## ğŸ§  **æ™ºèƒ½è·¯ç”±å†³ç­–å¼•æ“**

### âš¡ **è·¯ç”±å†³ç­–ç®—æ³•**
```python
class IntelligentRoutingEngine:
    """æ™ºèƒ½è·¯ç”±å†³ç­–å¼•æ“"""
    
    def __init__(self, registry: UnifiedToolRegistry):
        self.registry = registry
        self.discovery_engine = ToolDiscoveryEngine(registry)
        
        # å†³ç­–æƒé‡é…ç½®
        self.decision_weights = {
            "performance": 0.3,      # æ€§èƒ½æƒé‡
            "cost": 0.25,           # æˆæœ¬æƒé‡  
            "quality": 0.25,        # è´¨é‡æƒé‡
            "availability": 0.2     # å¯ç”¨æ€§æƒé‡
        }
    
    def select_optimal_tool(self, user_request: str, context: Dict = None) -> Dict:
        """é€‰æ‹©æœ€ä¼˜å·¥å…·"""
        context = context or {}
        
        # 1. å·¥å…·å‘ç°
        candidate_tools = self.discovery_engine.search_tools(
            user_request, 
            filters=context.get("filters", {})
        )
        
        if not candidate_tools:
            return {"success": False, "error": "æœªæ‰¾åˆ°åŒ¹é…çš„å·¥å…·"}
        
        # 2. å¤šç»´åº¦è¯„åˆ†
        scored_tools = []
        for tool in candidate_tools:
            score = self._calculate_comprehensive_score(tool, context)
            tool["comprehensive_score"] = score
            scored_tools.append(tool)
        
        # 3. é€‰æ‹©æœ€ä¼˜å·¥å…·
        best_tool = max(scored_tools, key=lambda x: x["comprehensive_score"])
        
        # 4. ç”Ÿæˆå†³ç­–è§£é‡Š
        decision_explanation = self._generate_decision_explanation(
            best_tool, scored_tools[:3], context
        )
        
        return {
            "success": True,
            "selected_tool": best_tool,
            "alternatives": scored_tools[1:4],  # å‰3ä¸ªå¤‡é€‰
            "decision_explanation": decision_explanation,
            "routing_metadata": {
                "total_candidates": len(candidate_tools),
                "decision_time": "< 100ms",
                "confidence_score": best_tool["comprehensive_score"]
            }
        }
    
    def _calculate_comprehensive_score(self, tool: Dict, context: Dict) -> float:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        scores = {}
        
        # 1. æ€§èƒ½è¯„åˆ†
        scores["performance"] = self._calculate_performance_score(tool)
        
        # 2. æˆæœ¬è¯„åˆ†
        scores["cost"] = self._calculate_cost_score(tool, context)
        
        # 3. è´¨é‡è¯„åˆ†
        scores["quality"] = self._calculate_quality_score(tool)
        
        # 4. å¯ç”¨æ€§è¯„åˆ†
        scores["availability"] = self._calculate_availability_score(tool, context)
        
        # 5. åŠ æƒç»¼åˆè¯„åˆ†
        comprehensive_score = sum(
            scores[dimension] * self.decision_weights[dimension]
            for dimension in scores
        )
        
        # 6. ç›¸å…³æ€§åŠ æˆ
        relevance_bonus = tool.get("relevance_score", 0) * 0.1
        
        return min(comprehensive_score + relevance_bonus, 1.0)
    
    def _calculate_performance_score(self, tool: Dict) -> float:
        """è®¡ç®—æ€§èƒ½è¯„åˆ†"""
        metrics = tool["performance_metrics"]
        
        # å“åº”æ—¶é—´è¯„åˆ† (è¶Šä½è¶Šå¥½)
        response_time_score = max(0, 1 - (metrics["avg_response_time"] / 5000))  # 5sä¸ºåŸºå‡†
        
        # æˆåŠŸç‡è¯„åˆ†
        success_rate_score = metrics["success_rate"]
        
        # ååé‡è¯„åˆ†
        throughput_score = min(metrics["throughput"] / 1000, 1.0)  # 1000 req/minä¸ºæ»¡åˆ†
        
        # å¯é æ€§è¯„åˆ†
        reliability_score = metrics["reliability_score"]
        
        return (response_time_score * 0.3 + success_rate_score * 0.3 + 
                throughput_score * 0.2 + reliability_score * 0.2)
    
    def _calculate_cost_score(self, tool: Dict, context: Dict) -> float:
        """è®¡ç®—æˆæœ¬è¯„åˆ†"""
        cost_model = tool["cost_model"]
        user_budget = context.get("budget", {"max_cost_per_call": 0.01})
        
        if cost_model["type"] == "free":
            return 1.0
        elif cost_model["type"] == "per_call":
            cost_ratio = cost_model["cost_per_call"] / user_budget["max_cost_per_call"]
            return max(0, 1 - cost_ratio)
        elif cost_model["type"] == "subscription":
            # åŸºäºæœˆåº¦é™åˆ¶è®¡ç®—å•æ¬¡æˆæœ¬
            if cost_model["monthly_limit"] > 0:
                estimated_cost_per_call = 10 / cost_model["monthly_limit"]  # å‡è®¾æœˆè´¹$10
                cost_ratio = estimated_cost_per_call / user_budget["max_cost_per_call"]
                return max(0, 1 - cost_ratio)
            else:
                return 0.8  # æ— é™åˆ¶è®¢é˜…ç»™äºˆè¾ƒé«˜åˆ†æ•°
        
        return 0.5  # æœªçŸ¥æˆæœ¬æ¨¡å‹
    
    def _calculate_quality_score(self, tool: Dict) -> float:
        """è®¡ç®—è´¨é‡è¯„åˆ†"""
        quality = tool["quality_scores"]
        
        # ç”¨æˆ·è¯„åˆ† (1-5 è½¬æ¢ä¸º 0-1)
        user_rating_score = (quality["user_rating"] - 1) / 4
        
        # æ–‡æ¡£è´¨é‡
        doc_quality_score = quality["documentation_quality"]
        
        # ç¤¾åŒºæ”¯æŒ
        community_score = quality["community_support"]
        
        # æ›´æ–°é¢‘ç‡
        update_score = quality["update_frequency"]
        
        return (user_rating_score * 0.4 + doc_quality_score * 0.2 + 
                community_score * 0.2 + update_score * 0.2)
    
    def _calculate_availability_score(self, tool: Dict, context: Dict) -> float:
        """è®¡ç®—å¯ç”¨æ€§è¯„åˆ†"""
        limitations = tool["limitations"]
        user_requirements = context.get("requirements", {})
        
        score = 1.0
        
        # é€Ÿç‡é™åˆ¶æ£€æŸ¥
        required_rate = user_requirements.get("required_rate", 100)  # calls/hour
        if limitations["rate_limit"] < required_rate:
            score *= 0.5
        
        # æ•°æ®å¤§å°é™åˆ¶æ£€æŸ¥
        required_data_size = user_requirements.get("data_size", 1)  # MB
        if limitations["data_size_limit"] < required_data_size:
            score *= 0.7
        
        # å¹¶å‘é™åˆ¶æ£€æŸ¥
        required_concurrent = user_requirements.get("concurrent_requests", 1)
        if limitations["concurrent_limit"] < required_concurrent:
            score *= 0.8
        
        # åœ°ç†é™åˆ¶æ£€æŸ¥
        user_location = user_requirements.get("location", "")
        if (user_location and limitations["geographic_restrictions"] and 
            user_location in limitations["geographic_restrictions"]):
            score *= 0.3
        
        return score
    
    def _generate_decision_explanation(self, selected_tool: Dict, 
                                     alternatives: List[Dict], context: Dict) -> Dict:
        """ç”Ÿæˆå†³ç­–è§£é‡Š"""
        return {
            "selected_tool": {
                "name": selected_tool["name"],
                "platform": selected_tool["platform"],
                "score": selected_tool["comprehensive_score"],
                "key_advantages": self._identify_key_advantages(selected_tool)
            },
            "decision_factors": {
                "primary_factor": self._identify_primary_factor(selected_tool),
                "performance_rank": self._get_performance_rank(selected_tool, alternatives),
                "cost_efficiency": self._get_cost_efficiency(selected_tool),
                "quality_rating": selected_tool["quality_scores"]["user_rating"]
            },
            "alternatives_summary": [
                {
                    "name": alt["name"],
                    "platform": alt["platform"], 
                    "score": alt["comprehensive_score"],
                    "why_not_selected": self._explain_why_not_selected(alt, selected_tool)
                }
                for alt in alternatives
            ]
        }
    
    def _identify_key_advantages(self, tool: Dict) -> List[str]:
        """è¯†åˆ«å…³é”®ä¼˜åŠ¿"""
        advantages = []
        
        if tool["cost_model"]["type"] == "free":
            advantages.append("å…è´¹ä½¿ç”¨")
        
        if tool["performance_metrics"]["success_rate"] > 0.95:
            advantages.append("é«˜å¯é æ€§")
        
        if tool["performance_metrics"]["avg_response_time"] < 500:
            advantages.append("å¿«é€Ÿå“åº”")
        
        if tool["quality_scores"]["user_rating"] > 4.0:
            advantages.append("ç”¨æˆ·å¥½è¯„")
        
        return advantages
    
    def _identify_primary_factor(self, tool: Dict) -> str:
        """è¯†åˆ«ä¸»è¦å†³ç­–å› ç´ """
        scores = {
            "performance": self._calculate_performance_score(tool),
            "cost": self._calculate_cost_score(tool, {}),
            "quality": self._calculate_quality_score(tool),
            "availability": self._calculate_availability_score(tool, {})
        }
        
        return max(scores, key=scores.get)
    
    def _get_performance_rank(self, tool: Dict, alternatives: List[Dict]) -> int:
        """è·å–æ€§èƒ½æ’å"""
        all_tools = [tool] + alternatives
        sorted_tools = sorted(all_tools, 
                            key=lambda x: x["performance_metrics"]["success_rate"], 
                            reverse=True)
        
        return sorted_tools.index(tool) + 1
    
    def _get_cost_efficiency(self, tool: Dict) -> str:
        """è·å–æˆæœ¬æ•ˆç‡æè¿°"""
        cost_model = tool["cost_model"]
        
        if cost_model["type"] == "free":
            return "å…è´¹"
        elif cost_model["cost_per_call"] < 0.001:
            return "æä½æˆæœ¬"
        elif cost_model["cost_per_call"] < 0.01:
            return "ä½æˆæœ¬"
        else:
            return "æ ‡å‡†æˆæœ¬"
    
    def _explain_why_not_selected(self, alternative: Dict, selected: Dict) -> str:
        """è§£é‡Šä¸ºä»€ä¹ˆæ²¡æœ‰é€‰æ‹©å¤‡é€‰æ–¹æ¡ˆ"""
        if alternative["comprehensive_score"] < selected["comprehensive_score"]:
            score_diff = selected["comprehensive_score"] - alternative["comprehensive_score"]
            if score_diff > 0.2:
                return "ç»¼åˆè¯„åˆ†æ˜¾è‘—è¾ƒä½"
            else:
                return "ç»¼åˆè¯„åˆ†ç•¥ä½"
        
        return "å…¶ä»–å› ç´ è€ƒè™‘"
```

## ğŸ”§ **MCPç»Ÿä¸€æ‰§è¡Œå¼•æ“**

### âš™ï¸ **ç»Ÿä¸€æ‰§è¡Œæ¶æ„**
```python
class MCPUnifiedExecutionEngine:
    """MCPç»Ÿä¸€æ‰§è¡Œå¼•æ“"""
    
    def __init__(self, registry: UnifiedToolRegistry):
        self.registry = registry
        self.routing_engine = IntelligentRoutingEngine(registry)
        
        # MCPå®¢æˆ·ç«¯æ± 
        self.mcp_clients = {
            "aci.dev": ACIDevMCPClient(),
            "mcp.so": MCPSoMCPClient(),
            "zapier": ZapierMCPAdapter()
        }
        
        # æ‰§è¡Œç»Ÿè®¡
        self.execution_stats = {
            "total_executions": 0,
            "platform_usage": {"aci.dev": 0, "mcp.so": 0, "zapier": 0},
            "success_rate": 0.0,
            "avg_execution_time": 0.0
        }
    
    async def execute_user_request(self, user_request: str, context: Dict = None) -> Dict:
        """æ‰§è¡Œç”¨æˆ·è¯·æ±‚"""
        context = context or {}
        execution_id = f"exec_{int(time.time())}"
        
        try:
            # 1. æ™ºèƒ½è·¯ç”±é€‰æ‹©å·¥å…·
            routing_result = self.routing_engine.select_optimal_tool(user_request, context)
            
            if not routing_result["success"]:
                return routing_result
            
            selected_tool = routing_result["selected_tool"]
            
            # 2. å‡†å¤‡æ‰§è¡Œå‚æ•°
            execution_params = self._prepare_execution_params(
                user_request, selected_tool, context
            )
            
            # 3. é€šè¿‡MCPåè®®æ‰§è¡Œ
            execution_result = await self._execute_via_mcp(
                selected_tool, execution_params, execution_id
            )
            
            # 4. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_execution_stats(selected_tool, execution_result)
            
            # 5. è¿”å›å®Œæ•´ç»“æœ
            return {
                "success": True,
                "execution_id": execution_id,
                "selected_tool": {
                    "name": selected_tool["name"],
                    "platform": selected_tool["platform"],
                    "confidence_score": selected_tool["comprehensive_score"]
                },
                "execution_result": execution_result,
                "routing_info": routing_result["decision_explanation"],
                "alternatives": routing_result["alternatives"]
            }
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œå¤±è´¥ {execution_id}: {e}")
            return {
                "success": False,
                "execution_id": execution_id,
                "error": str(e),
                "error_type": "execution_error"
            }
    
    def _prepare_execution_params(self, user_request: str, tool: Dict, context: Dict) -> Dict:
        """å‡†å¤‡æ‰§è¡Œå‚æ•°"""
        # åŸºäºå·¥å…·çš„è¾“å…¥æ¨¡å¼å‡†å¤‡å‚æ•°
        input_schema = tool["input_schema"]
        
        # ç®€åŒ–çš„å‚æ•°æ˜ å°„é€»è¾‘
        params = {
            "request": user_request,
            "context": context,
            "tool_specific_params": self._extract_tool_specific_params(
                user_request, tool, context
            )
        }
        
        return params
    
    def _extract_tool_specific_params(self, request: str, tool: Dict, context: Dict) -> Dict:
        """æå–å·¥å…·ç‰¹å®šå‚æ•°"""
        # åŸºäºå·¥å…·ç±»å‹å’Œèƒ½åŠ›æå–å‚æ•°
        tool_params = {}
        
        # æ ¹æ®å·¥å…·ç±»åˆ«è®¾ç½®é»˜è®¤å‚æ•°
        category = tool["category"]
        
        if category == "productivity":
            tool_params.update({
                "priority": context.get("priority", "normal"),
                "deadline": context.get("deadline"),
                "notification": context.get("notification", True)
            })
        elif category == "data_analysis":
            tool_params.update({
                "analysis_type": context.get("analysis_type", "basic"),
                "output_format": context.get("output_format", "json"),
                "include_visualization": context.get("visualization", False)
            })
        elif category == "communication":
            tool_params.update({
                "recipients": context.get("recipients", []),
                "message_format": context.get("format", "text"),
                "urgent": context.get("urgent", False)
            })
        
        return tool_params
    
    async def _execute_via_mcp(self, tool: Dict, params: Dict, execution_id: str) -> Dict:
        """é€šè¿‡MCPåè®®æ‰§è¡Œå·¥å…·"""
        platform = tool["platform"]
        mcp_client = self.mcp_clients[platform]
        
        start_time = time.time()
        
        try:
            # æ„å»ºMCPè¯·æ±‚
            mcp_request = {
                "tool_id": tool["platform_tool_id"],
                "parameters": params,
                "execution_id": execution_id,
                "timeout": 30  # 30ç§’è¶…æ—¶
            }
            
            # æ‰§è¡ŒMCPè°ƒç”¨
            mcp_response = await mcp_client.execute_tool(mcp_request)
            
            execution_time = time.time() - start_time
            
            # æ ‡å‡†åŒ–å“åº”æ ¼å¼
            standardized_response = self._standardize_response(
                mcp_response, tool, execution_time
            )
            
            return standardized_response
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"MCPæ‰§è¡Œå¤±è´¥ {execution_id}: {e}")
            
            return {
                "success": False,
                "error": str(e),
                "execution_time": execution_time,
                "platform": platform,
                "tool_id": tool["id"]
            }
    
    def _standardize_response(self, mcp_response: Dict, tool: Dict, execution_time: float) -> Dict:
        """æ ‡å‡†åŒ–å“åº”æ ¼å¼"""
        return {
            "success": mcp_response.get("success", True),
            "result": mcp_response.get("result", mcp_response),
            "execution_time": execution_time,
            "platform": tool["platform"],
            "tool_name": tool["name"],
            "tool_id": tool["id"],
            "metadata": {
                "response_size": len(str(mcp_response)),
                "execution_timestamp": time.time(),
                "mcp_version": mcp_response.get("mcp_version", "1.0")
            }
        }
    
    def _update_execution_stats(self, tool: Dict, result: Dict):
        """æ›´æ–°æ‰§è¡Œç»Ÿè®¡"""
        self.execution_stats["total_executions"] += 1
        self.execution_stats["platform_usage"][tool["platform"]] += 1
        
        # æ›´æ–°æˆåŠŸç‡
        if result.get("success"):
            current_success = self.execution_stats.get("successful_executions", 0)
            self.execution_stats["successful_executions"] = current_success + 1
        
        total = self.execution_stats["total_executions"]
        successful = self.execution_stats.get("successful_executions", 0)
        self.execution_stats["success_rate"] = successful / total
        
        # æ›´æ–°å¹³å‡æ‰§è¡Œæ—¶é—´
        current_avg = self.execution_stats["avg_execution_time"]
        new_time = result.get("execution_time", 0)
        self.execution_stats["avg_execution_time"] = (
            (current_avg * (total - 1) + new_time) / total
        )
    
    def get_execution_statistics(self) -> Dict:
        """è·å–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        return {
            "statistics": self.execution_stats,
            "platform_distribution": {
                platform: count / max(self.execution_stats["total_executions"], 1)
                for platform, count in self.execution_stats["platform_usage"].items()
            },
            "registry_info": {
                "total_tools": len(self.registry.tools_db),
                "platform_breakdown": self._get_platform_breakdown()
            }
        }
    
    def _get_platform_breakdown(self) -> Dict:
        """è·å–å¹³å°å·¥å…·åˆ†å¸ƒ"""
        breakdown = {"aci.dev": 0, "mcp.so": 0, "zapier": 0}
        
        for tool in self.registry.tools_db.values():
            platform = tool["platform"]
            if platform in breakdown:
                breakdown[platform] += 1
        
        return breakdown
```

## ğŸ¯ **å®Œæ•´ä½¿ç”¨ç¤ºä¾‹**

### ğŸ“ **ç¤ºä¾‹1ï¼šæ™ºèƒ½æ•°æ®åˆ†æ**
```python
# ç”¨æˆ·è¯·æ±‚
user_request = "åˆ†ææˆ‘çš„é”€å”®æ•°æ®å¹¶ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š"

# æ‰§è¡Œä¸Šä¸‹æ–‡
context = {
    "budget": {"max_cost_per_call": 0.005},
    "requirements": {
        "data_size": 5,  # 5MBæ•°æ®
        "required_rate": 50,  # 50 calls/hour
        "output_format": "pdf"
    },
    "filters": {
        "categories": ["data_analysis", "visualization"],
        "min_success_rate": 0.9
    }
}

# æ‰§è¡Œè¯·æ±‚
execution_engine = MCPUnifiedExecutionEngine(registry)
result = await execution_engine.execute_user_request(user_request, context)

# ç»“æœç¤ºä¾‹
{
    "success": True,
    "execution_id": "exec_1704363600",
    "selected_tool": {
        "name": "advanced_data_analyzer",
        "platform": "mcp.so",
        "confidence_score": 0.87
    },
    "execution_result": {
        "success": True,
        "result": {
            "analysis_summary": "é”€å”®æ•°æ®åˆ†æå®Œæˆ",
            "visualizations": ["chart1.png", "chart2.png"],
            "report_url": "https://reports.mcp.so/abc123.pdf"
        },
        "execution_time": 2.3,
        "platform": "mcp.so"
    },
    "routing_info": {
        "selected_tool": {
            "name": "advanced_data_analyzer",
            "platform": "mcp.so",
            "key_advantages": ["é«˜å¯é æ€§", "ä¸“ä¸šåˆ†æ", "ç”¨æˆ·å¥½è¯„"]
        },
        "decision_factors": {
            "primary_factor": "quality",
            "performance_rank": 2,
            "cost_efficiency": "ä½æˆæœ¬"
        }
    },
    "alternatives": [
        {
            "name": "google_sheets_analyzer",
            "platform": "aci.dev",
            "score": 0.82,
            "why_not_selected": "åˆ†ææ·±åº¦ä¸è¶³"
        }
    ]
}
```

### ğŸ“ **ç¤ºä¾‹2ï¼šå›¢é˜Ÿåä½œè‡ªåŠ¨åŒ–**
```python
# ç”¨æˆ·è¯·æ±‚
user_request = "å½“æœ‰æ–°çš„GitHub PRæ—¶ï¼Œè‡ªåŠ¨é€šçŸ¥Slackå›¢é˜Ÿå¹¶åˆ›å»ºJiraä»»åŠ¡"

# æ‰§è¡Œä¸Šä¸‹æ–‡
context = {
    "budget": {"max_cost_per_call": 0.0},  # å¸Œæœ›å…è´¹
    "requirements": {
        "workflow_automation": True,
        "integration_count": 3  # GitHub + Slack + Jira
    },
    "filters": {
        "platforms": ["zapier", "aci.dev"],  # åå¥½è¿™ä¸¤ä¸ªå¹³å°
        "categories": ["automation", "communication", "development"]
    }
}

# æ‰§è¡Œç»“æœ
{
    "success": True,
    "selected_tool": {
        "name": "github_slack_jira_workflow",
        "platform": "zapier",
        "confidence_score": 0.94
    },
    "routing_info": {
        "decision_factors": {
            "primary_factor": "workflow_automation",
            "key_advantages": ["å…è´¹ä½¿ç”¨", "å¤šå¹³å°é›†æˆ", "å¯è§†åŒ–é…ç½®"]
        }
    }
}
```

## ğŸ’¡ **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**

### âœ… **1. ç»Ÿä¸€ç®¡ç†**
- å•ä¸€å·¥å…·æ³¨å†Œè¡¨ç®¡ç†æ‰€æœ‰å¹³å°å·¥å…·
- æ ‡å‡†åŒ–çš„å·¥å…·å…ƒæ•°æ®å’Œè¯„åˆ†ä½“ç³»
- ç»Ÿä¸€çš„æœç´¢å’Œå‘ç°æ¥å£

### âœ… **2. æ™ºèƒ½å†³ç­–**
- å¤šç»´åº¦è¯„åˆ†ç®—æ³•ï¼ˆæ€§èƒ½ã€æˆæœ¬ã€è´¨é‡ã€å¯ç”¨æ€§ï¼‰
- ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å·¥å…·é€‰æ‹©
- é€æ˜çš„å†³ç­–è§£é‡Šå’Œå¤‡é€‰æ–¹æ¡ˆ

### âœ… **3. æ— ç¼æ‰§è¡Œ**
- ç»Ÿä¸€çš„MCPåè®®æ¥å£
- å¹³å°æ— å…³çš„æ‰§è¡Œä½“éªŒ
- æ ‡å‡†åŒ–çš„å“åº”æ ¼å¼

### âœ… **4. æŒç»­ä¼˜åŒ–**
- å®æ—¶æ‰§è¡Œç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§
- åŸºäºä½¿ç”¨æ•°æ®çš„å·¥å…·æ¨èä¼˜åŒ–
- åŠ¨æ€çš„å¹³å°è´Ÿè½½å‡è¡¡

**è¿™ä¸ªé‡æ–°è®¾è®¡çš„æ¶æ„å®ç°äº†çœŸæ­£çš„"ç»Ÿä¸€å·¥å…·æ³¨å†Œè¡¨ + æ™ºèƒ½è·¯ç”± + MCPç»Ÿä¸€æ‰§è¡Œ"ï¼Œä¸ºç”¨æˆ·æä¾›æœ€ä¼˜çš„å·¥å…·é€‰æ‹©å’Œæ— ç¼çš„æ‰§è¡Œä½“éªŒï¼**

