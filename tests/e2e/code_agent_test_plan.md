# 代码智能体端到端测试方案 (基于视觉验证与自动化操作)

## 1. 测试目标

验证代码智能体在接收用户需求、分析问题、生成代码、调试代码以及与开发工具（如AgentProblemSolver、TestAndIssueCollector）交互等核心功能的端到端流程。

**重点验证：**

* **视觉一致性：** 生成的代码、IDE界面、调试输出、错误提示等视觉元素是否符合预期。
* **自动化操作：** 通过API调用或模拟用户交互触发代码生成和执行流程，并自动完成结果校验。
* **功能完整性：** 覆盖代码生成、语法检查、执行、调试、错误处理等场景。
* **模块集成：** 验证代码智能体与六大MCP模块、开发工具模块的集成。

## 2. 测试环境

* **平台版本：** PowerAutomation 增强版 (当前开发版本)
* **运行环境：** 沙盒环境 (Ubuntu 22.04)
* **依赖服务：**
  * PowerAutomation后端服务 (包含代码智能体API)
  * 代码执行环境 (Python, JavaScript等)
  * (可选) PowerAutomation前端服务 (如果测试涉及UI交互)
* **测试工具：**
  * `TestAndIssueCollector`: 用于执行测试流程、截图、视觉比对、生成报告、提交问题。
  * `ThoughtActionRecorder`: 用于记录智能体思考和操作日志。
  * `AgentProblemSolver`: 用于接收和处理测试中发现的问题。
  * Python `requests` 库: 用于API调用。
  * (可选) UI自动化工具 (如 Playwright): 如果需要模拟前端交互。
  * 图像处理库 (如 PIL): 用于截图比对。

## 3. 测试用例设计

**核心原则：** 每个测试用例都强调视觉验证和自动化操作，避免仅依赖脚本输出。

### 用例1：基本代码生成与视觉验证

* **ID:** E2E-CODE-001
* **描述:** 测试代码智能体生成一个简单Python程序的基本功能。
* **输入:** 通过API向代码智能体发送请求，要求生成"一个计算斐波那契数列的Python函数"。
* **自动化步骤:**
  1. 启动PowerAutomation后端服务。
  2. 使用`requests`调用代码智能体API，发送生成请求。
  3. 轮询检查代码文件是否在指定目录生成。
  4. 使用`TestAndIssueCollector`：
     * 记录测试开始。
     * 打开生成的Python文件（使用IDE或编辑器）。
     * 调用`take_screenshot`，保存为`e2e_code_001_editor_actual.png`。
     * 执行生成的代码（例如，调用斐波那契函数计算第10个数）。
     * 调用`take_screenshot`，保存为`e2e_code_001_execution_actual.png`。
     * (假设有基准图片) 调用`compare_screenshots`将实际截图与预定义的基准截图进行比较。
     * 记录比较结果。
* **视觉验证点:**
  * 编辑器截图：检查代码是否包含斐波那契函数定义，语法是否正确，注释是否清晰。
  * 执行截图：检查代码执行结果是否正确显示斐波那契数列。
  * 截图比对结果：`diff_percentage`是否在可接受范围内（例如 < 5%）。
* **预期结果:**
  * 成功生成Python代码文件。
  * 代码可以正确执行并输出预期结果。
  * 截图比对成功（或视觉检查通过）。
  * `TestAndIssueCollector`报告测试通过。
  * `ThoughtActionRecorder`记录了完整的思考和操作流程。
* **失败处理:**
  * 如果代码未生成、执行失败或截图比对失败，`TestAndIssueCollector`记录问题，生成失败报告，并将问题信息（包括截图、日志）提交给`AgentProblemSolver`。

### 用例2：代码调试与错误修复流程验证

* **ID:** E2E-CODE-002
* **描述:** 测试代码智能体识别和修复代码错误的能力。
* **输入:** 通过API提供一段包含错误的Python代码（例如，一个有bug的排序算法）。
* **自动化步骤:**
  1. 启动后端服务。
  2. 使用`requests`调用代码智能体API，发送包含错误代码的请求，要求修复。
  3. 轮询检查修复后的代码文件是否生成。
  4. 使用`TestAndIssueCollector`：
     * 记录测试开始。
     * 打开原始错误代码和修复后的代码（并排显示）。
     * 调用`take_screenshot`，保存为`e2e_code_002_diff_actual.png`。
     * 执行修复后的代码。
     * 调用`take_screenshot`，保存为`e2e_code_002_fixed_execution_actual.png`。
     * 调用`compare_screenshots`将实际截图与基准截图进行比较。
     * 记录比较结果。
* **视觉验证点:**
  * 代码对比截图：检查是否正确识别并修复了错误（例如，排序算法的bug）。
  * 执行截图：检查修复后的代码是否正确执行（例如，排序结果正确）。
  * 截图比对结果。
* **预期结果:**
  * 成功识别并修复代码错误。
  * 修复后的代码可以正确执行。
  * 截图比对成功（或视觉检查通过）。
  * `TestAndIssueCollector`报告测试通过。
* **失败处理:** 同用例1。

### 用例3：MCP模块集成验证 - 上下文匹配优化

* **ID:** E2E-CODE-003
* **描述:** 测试代码智能体与上下文匹配优化MCP模块的集成。
* **输入:** 通过API提供一个需要上下文理解的代码生成任务（例如，"为电商网站添加购物车功能"，同时提供网站的部分现有代码）。
* **自动化步骤:**
  1. 启动后端服务。
  2. 使用`requests`调用代码智能体API，发送请求，包含任务描述和现有代码。
  3. 轮询检查生成的代码文件。
  4. 使用`TestAndIssueCollector`：
     * 记录测试开始。
     * 打开生成的代码。
     * 调用`take_screenshot`，保存为`e2e_code_003_context_actual.png`。
     * 检查代码是否与现有代码风格一致，是否正确引用了现有变量和函数。
     * 调用`compare_screenshots`将实际截图与基准截图进行比较。
     * 记录比较结果。
* **视觉验证点:**
  * 代码截图：检查生成的代码是否与现有代码风格一致，是否正确引用了现有变量和函数。
  * 截图比对结果。
* **预期结果:**
  * 生成的代码与现有代码风格一致。
  * 生成的代码正确引用了现有变量和函数。
  * 截图比对成功（或视觉检查通过）。
  * `TestAndIssueCollector`报告测试通过。
* **失败处理:** 同用例1。

### 用例4：多语言代码生成能力验证

* **ID:** E2E-CODE-004
* **描述:** 测试代码智能体生成多种编程语言代码的能力。
* **输入:** 通过API请求生成同一功能的多语言实现（例如，"实现一个简单的HTTP服务器，分别用Python、JavaScript和Go语言"）。
* **自动化步骤:**
  1. 启动后端服务。
  2. 使用`requests`调用代码智能体API，发送多语言代码生成请求。
  3. 轮询检查生成的多个代码文件。
  4. 使用`TestAndIssueCollector`：
     * 记录测试开始。
     * 依次打开各语言的代码文件。
     * 为每种语言调用`take_screenshot`，保存为`e2e_code_004_python_actual.png`、`e2e_code_004_javascript_actual.png`、`e2e_code_004_go_actual.png`。
     * 尝试执行每种语言的代码（如果环境支持）。
     * 调用`compare_screenshots`将实际截图与基准截图进行比较。
     * 记录比较结果。
* **视觉验证点:**
  * 各语言代码截图：检查代码是否符合各语言的语法和最佳实践。
  * 执行截图（如果可行）：检查代码是否可以正确执行。
  * 截图比对结果。
* **预期结果:**
  * 成功生成多种语言的代码文件。
  * 各语言代码符合语法和最佳实践。
  * 截图比对成功（或视觉检查通过）。
  * `TestAndIssueCollector`报告测试通过。
* **失败处理:** 同用例1。

## 4. 测试执行与报告

1. **执行:**
   * 创建一个主测试脚本（例如 `run_code_e2e_tests.py`）。
   * 该脚本依次执行上述测试用例。
   * 脚本负责启动/停止依赖服务，调用API，并驱动`TestAndIssueCollector`完成测试步骤（截图、比对、记录）。
2. **报告:**
   * 每个用例执行后，`TestAndIssueCollector`记录结果。
   * 所有用例执行完毕后，`TestAndIssueCollector`调用`generate_test_report`生成最终的Markdown格式测试报告。
   * 报告应包含每个用例的执行状态、关键截图（或差异图）、比对结果、日志摘要。
3. **问题处理:**
   * 测试脚本检查每个用例的`TestAndIssueCollector`返回结果。
   * 如果检测到失败（如截图比对失败、API错误未按预期处理），则调用`TestAndIssueCollector.collect_issues`收集详细信息，并通过`TestAndIssueCollector.submit_issues_to_problem_solver`将问题提交给`AgentProblemSolver`。

## 5. 基准图片管理

* 为需要进行视觉比对的测试用例准备基准截图（Baseline Screenshots）。
* 首次运行测试或UI/编辑器更新后，需要生成或更新基准图片。
* 基准图片应存储在版本控制中，与测试代码一起管理。

## 6. 文档维护

* 本测试方案文档 (`code_agent_test_plan.md`) 应随代码一同维护。
* 当代码智能体功能、API或依赖发生变化时，及时更新测试方案和测试用例。
